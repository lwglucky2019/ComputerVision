#  第四章 拟合概率模型 （1）

[TOC]

## 1. 最大似然估计(MLE)

最大似然估计，英文为Maximum Likelihood Estimation，简写为MLE，也叫极大似然估计，是用来估计概率模型参数的一种方法。最大似然估计的思想是使得观测数据（样本）发生概率最大的参数就是最好的参数。

$$ \begin{array}{c}
\hat \theta=\mathop{argmax} \limits_{\theta}P(x|\theta) \\
 =\mathop{argmax} \limits_{\theta} \left[ {\prod\limits_{i = 1}^l {P({x_i}|\theta )} } \right] \tag{1.1}
 \end{array} $$

-------------------------

https://www.jianshu.com/p/9c153d82ba2d

## 2. 最大后验概率 (MAP:Maximum A Posteriori Estimation)

最大后验概率分布认为$\theta$是一个随机变量，即$\theta$具有某种概率分布，称为先验分布，求解时除了要考虑似然函数$P(X|\theta)$之外，还要考虑$\theta$的先验分布$P(\theta)$，因此其认为使$P(X|\theta)P(\theta)$取最大值的$\theta$就是最好的$\theta$。此时要最大化的函数变为$P(X|\theta)P(\theta)$，由于$X$的先验分布$P(X)$是固定的（可通过分析数据获得，其实我们也不关心X的分布，我们关心的是$\theta$），因此最大化函数可变为$\frac {P(X|\theta)P(\theta)} {P(X)}$，根据贝叶斯法则，要最大化的函数$\frac {P(X|\theta)P(\theta)} {P(X)}=P(\theta|X)$，因此要最大化的函数是$P(\theta|X)$，而$P(\theta|X)$是$\theta$的后验概率。最大后验概率估计可以看作是正则化的最大似然估计，当然机器学习或深度学习中的正则项通常是加法，而在最大后验概率估计中采用的是乘法，$P(\theta)$是正则项。

最大后验概率估计的公式表示：
$$ \begin{array}{c}
\mathop{argmax} \limits_{\theta}P(\theta|X)=\mathop{argmax} \limits_{\theta}\frac {P(X|\theta)P(\theta)} {P(X)} \\ \propto \mathop{argmax} \limits_{\theta}P(X|\theta)P(\theta)  \\ =\mathop{argmax} \limits_{\theta} \left[ {\prod\limits_{i = 1}^l {P({x_i}|\theta )P(\theta)} }   \right]
 \tag{2.1}  \end{array} $$

-------------------------

## 3. 贝叶斯方法

贝叶斯估计是最大后验估计的进一步扩展，贝叶斯估计同样假定$\theta$是一个随机变量，但贝叶斯估计并不是直接估计出$\theta$的某个特定值，而是估计$\theta$的分布，这是贝叶斯估计与最大后验概率估计不同的地方。在贝叶斯估计中，先验分布P(X)是不可忽略的。
贝叶斯公式：
$$ P(\theta|X)=\frac {P(X|\theta)P(\theta)} {P(X)}  \tag{3.1}$$

在连续型随机变量中，由于$P(X)=\int_{\Theta}P(X|\theta)P(\theta)d\theta$，因此贝叶斯公式变为：
$$
P(\theta|X)=\frac {P(X|\theta)P(\theta)} {\int_{\Theta}P(X|\theta)P(\theta)d\theta} \tag{3.2}
$$

从上面的公式中可以看出，贝叶斯估计的求解非常复杂，因此选择合适的先验分布就非常重要。一般来说，计算积分$\int_{\theta}P(X|\theta)P(\theta)d\theta$是不可能的。对于这个抛硬币的例子来说，如果使用共轭先验分布，就可以更好的解决这个问题。二项分布参数的共轭先验是Beta分布，由于$\theta$的似然函数服从二项分布，因此在贝叶斯估计中，假设$\theta$的先验分布服从$P(\theta)\sim Beta(\alpha, \beta)$，$Beta$分布的概率密度公式为：
$$f(x;\alpha,\beta)=\frac {1} {B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1} \tag{3.3}$$
因此，贝叶斯公式可写作：
$$
\begin{aligned} P(\theta|X)&=\frac {P(X|\theta)P(\theta)} {\int_{\Theta}P(X|\theta)P(\theta)d\theta} \\\\ &=\frac {\theta^6(1-\theta)^4 \frac {\theta^{\alpha-1}(1-\theta)^{\beta-1}} {B(\alpha,\beta)} } {\int_{\Theta}\theta^6(1-\theta)^4 \frac {\theta^{\alpha-1}(1-\theta)^{\beta-1}} {B(\alpha,\beta)}d\theta} \\\\&=\frac {\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}} {\int_{\Theta}\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}d\theta} \\\\ &=\frac {\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}} {B(\alpha+6-1,\beta+4-1)} \\\\ &=Beta(\theta|\alpha+6-1,\beta+4-1) \\\\&=Beta(\theta|\alpha+6,\beta+4)\end{aligned}  \tag{3.4}
$$
从上面的公式可以看出，$P(\theta|X) \sim Beta(\theta|\alpha+6,\beta+4)$。其中$B$函数，也称$Beta$函数，是一个标准化常量，用来使整个概率的积分为1。$Beta(\theta|\alpha+6,\beta+4)$就是贝叶斯估计的结果。

![beta](https://raw.githubusercontent.com/lwglucky/BLOG/master/20190920120559.png)

--------------------------

* 例子
  * 最大似然估计 : 以抛硬币为例，假设我们有一枚硬币，现在要估计其正面朝上的概率$\theta$。为了对$\theta$进行估计，我们进行了10次实验（独立同分布，i.i.d.），这组实验记为$X=x_1，x_2，\ldots，x_{10}$，其中正面朝上的次数为6次，反面朝上的次数为4次，结果为$(1,0,1,1,0,0,0,1,1,1)$。
  
  对一个独立同分布的样本集来说，总体的似然就是每个样本似然的乘积。针对抛硬币的问题，似然函数可写作：
  $$ L(X;\theta)=\prod_{i=0}^nP(x_i|\theta)=\theta^6(1-\theta)^4 $$
  根据最大似然估计，使$L(X;\theta)$取得最大值的$\theta$即为估计结果，令$L(X;\theta)\prime =0$可得$ \hat{\theta}=0.6 $。 

  * 最大后验概率估计: 抛硬币通常认为$\theta=0.5$的可能性最大，因此我们用均值为0.5，方差为0.1的高斯分布来描述$\theta$的先验分布，当然也可以使用其它的分布来描述$\theta$的先验分布。$\theta$的先验分布为：
  $$
  \frac {1} {\sqrt{2\pi}\sigma}e^{-\frac {(\theta-\mu)^2} {2\sigma^2}} = \frac {1} {10\sqrt{2\pi}}e^{-50(\theta-0.5)^2}
  $$
在最大似然估计中，已知似然函数为$P(X|\theta)=\theta^6(1-\theta)^4$，因此：
$$
P(X|\theta)P(\theta)=\theta^6\times (1-\theta)^4\times \frac {1} {10\sqrt{2\pi}}\times e^{-50(\theta-0.5)^2}
$$
转换为对数函数：
$$\begin{aligned} 
ln(P(X|\theta)P(\theta))= ln(\theta^6\times (1-\theta)^4 \times \frac {1} {10\sqrt{2\pi}}\times e^{-50(\theta-0.5)^2}) \\
=6ln(\theta)+4ln(1-\theta)+ln(\frac {1} {10\sqrt{2\pi}})-50(\theta-0.5)^2 \end{aligned} $$

令$ln(P(X|\theta)P(\theta))\prime=0$，可得：
$$ 100\theta^3-150\theta^2+40\theta+6=0 $$
由于$0\le\theta\le1$，解得：$\hat{\theta}\approx0.529$。

  * 贝叶斯方法:  
$$
\begin{aligned} P(\theta|X)&=\frac {P(X|\theta)P(\theta)} {\int_{\Theta}P(X|\theta)P(\theta)d\theta} \\\\ &=\frac {\theta^6(1-\theta)^4 \frac {\theta^{\alpha-1}(1-\theta)^{\beta-1}} {B(\alpha,\beta)} } {\int_{\Theta}\theta^6(1-\theta)^4 \frac {\theta^{\alpha-1}(1-\theta)^{\beta-1}} {B(\alpha,\beta)}d\theta} \\\\&=\frac {\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}} {\int_{\Theta}\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}d\theta} \\\\ &=\frac {\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}} {B(\alpha+6-1,\beta+4-1)} \\\\ &=Beta(\theta|\alpha+6-1,\beta+4-1) \\\\&=Beta(\theta|\alpha+6,\beta+4)\end{aligned}
$$