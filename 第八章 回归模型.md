# 第8章回归模型▲＊	2
        
[TOC]
        
## 1.  线性回归（Linear Regression）

$$ 回归公式：  f(X) = {W^T}X + b  \tag{1.0} $$ 

其中数据集 $D=\{(x_1,y_1),(x_2,y_2),...,(x_i,y_i)\}$,为了使回归函数与数据集误差最小，则误差函数最小为：
$$ 误差： E_{(w,b)}= \sum\limits_{i = 1}^m {(y_i-w^Tx_i-b)^2}  \tag{1.1}$$
$$ 或者： (w^*,b^*)= \mathop {argmin }\limits_{(w,b)}\sum\limits_{i = 1}^m {{{({y_i} - w{x_i} - b)}^2}} \tag{1.2}$$
 对(1.2)公式求导，并令导数为0：
 $$\left\{ \begin{array}{l}
\frac{{\partial {E_{(w,b)}}}}{{\partial w}} = 2\left( {w\sum\limits_{i = 1}^m {x_i^2}  - \sum\limits_{i = 1}^m {({y_i} - b)} {x_i}} \right)\\
\frac{{\partial {E_{(w,b)}}}}{{\partial b}} = 2\left( {mb - \sum\limits_{i = 1}^m {({y_i} - w{x_i})} } \right)
\end{array} \right.  \tag{1.3}$$

最后得到封闭解(closed-form):
$$ \left\{ \begin{array}{l}
w^* = \frac{{\sum\limits_{i = 1}^m {{y_i}({x_i} - \bar x)} }}{{\sum\limits_{i = 1}^m {x_i^2 - \frac{1}{m}{{(\sum\limits_{i = 1}^m {x_i^{}} )}^2}} }}\\
b^* = \frac{1}{m}\sum\limits_{i = 1}^m {({y_i} - w{x_i})} 
\end{array} \right. \tag{1.4}$$



  上面的计算方法是数据计算方法，并不适合向量矩阵的并行运算,以矩阵形式的表达，令$\hat w=(w;b) , \hat b=(b;1)$,则(1.1)公式的矩阵表达形式为：
$$ \hat w^*=\mathop {argmin }\limits_{w}(y-X\hat w)^T(y-X\hat w)    \tag{1.5}$$
$$ \begin{array}{c} {E_{\hat w}=(y-X\hat w)^T(y-X\hat w)}\\
= y^Ty-y^TX\hat w - \hat w^TX^Ty - \hat w^TX^TX\hat w \end{array}  \tag{1.6} $$

求解$\frac{{\partial {E_{\hat w}}}}{{\partial \hat w}} = 2{X^T}(X\hat w - y)=0 $, 求解得到：
$$ {E_{\hat w}=(X^TX)^{-1}X^Ty} \tag{1.7}$$
这里矩阵求导公式有：
$$ \frac{{\partial Ax}}{{\partial x}} = {A^T},  \frac{{\partial x^TA}}{{\partial x}} = A,  \frac{{\partial {w^T}{X^T}Xw}}{{\partial w}} = 2{X^T}Xw  $$


![回归](https://raw.githubusercontent.com/lwglucky/BLOG/master/20190922231135.png)  

        
        8.1	线性回归	 
        8.2	贝叶斯线性回归 	
        8.3	非线性回归