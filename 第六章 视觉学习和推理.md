# 第6章视觉学习和推理 (0.5)

[TOC]


## 判别模型

判别模型（Discriminative Model），又可以称为条件模型，或条件概率模型。估计的是条件概率分布(conditional distribution)，$p(class|context)$。利用正负例和分类标签，主要关心判别模型的边缘分布。其目标函数直接对应于分类准确率。 （判别模型多数放在分类）
        主要特点：寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。
+ 优点：
1. 分类边界更灵活，比使用纯概率方法或生产模型得到的更高级；
2. 能清晰的分辨出多类或某一类与其他类之间的差异特征；
3. 在聚类、视角变化、部分遮挡、尺度改变等方面效果较好；
4. 适用于较多类别的识别；
5. 判别模型的性能比生成模型要简单，比较容易学习。
   
+ 缺点：
1. 不能反映训练数据本身的特性，即能力有限，可以告诉你的是1还是2，但没有办法把整个场景描述出来；
2. 缺少生成模型的优点，即先验结构的不确定性；
3. 黑盒操作，即变量间的关系不清楚，不可视。

常见的主要有：
        logistic regression、SVM、traditional neural networks、Nearest neighbor、Conditional random fields。
主要应用：
        Image and document classification、Biosequence analysis、Time series prediction。



## 生成模型

生成模型（Generative Model），又叫产生式模型。估计的是联合概率分布（joint probability distribution），$p(class, context)=p(class|context)*p(context)$。用于随机生成的观察值建模，特别是在给定某些隐藏参数情况下。在机器学习中，或用于直接对数据建模（用概率密度函数对观察到的样本数据建模），或作为生成条件概率密度函数的中间步骤。通过使用贝叶斯规则可以从生成模型中得到条件分布。如果观察到的数据是完全由生成模型所生成的，那么就可以拟合生成模型的参数，从而仅可能的增加数据相似度。但数据很少能由生成模型完全得到，所以比较准确的方式是直接对条件密度函数建模，即使用分类或回归分析。与描述模型的不同是，描述模型中所有变量都是直接测量得到。 

+ 主要特点：
1. 一般主要是对后验概率建模，从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度；
2. 只关注自己的类本身（即点左下角区域内的概率），不关心到底决策边界在哪。

+ 优点：
1. 实际上带的信息要比判别模型丰富；
2. 研究单类问题比判别模型灵活性强；
3. 模型可以通过增量学习得到；
4. 能用于数据不完整（missing data）情况；
5. 很容易将先验知识考虑进去。

+ 缺点：
1. 容易会产生错误分类；
2. 学习和计算过程比较复杂。

常见的主要有：
        Gaussians、Naive Bayes、Mixtures of multinomials、Mixtures of Gaussians、Mixtures of experts、HMMs、Sigmoidal belief networks、Bayesian networks、Markov random fields。